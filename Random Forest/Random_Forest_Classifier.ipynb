{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoOwWA8Jomxl"
      },
      "source": [
        "# Random Forest Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksmMsvVLoclX"
      },
      "source": [
        "Random forests are known as ensemble learning methods used for classification and regression. Random forests are essentially a collection of decision trees that are each fit on a subsample of the data. While an individual tree is typically noisey and subject to high variance, random forests average many different trees, which in turn reduces the variability and leave us with a powerful classifier.\n",
        "\n",
        "Random forests are also non-parametric and require little to no parameter tuning. They differ from many common machine learning models used today that are typically optimized using gradient descent. Models like linear regression, support vector machines, neural networks, etc. require a lot of matrix based operations, while tree based models like random forest are constructed with basic arithmetic. In other words, to build a tree all we're really doing is selecting a hand full of observations from out dataset, picking a few features to look through, and finding the value that makes the best split in our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwzXJSw-zjqn"
      },
      "source": [
        "# Complete code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tke2VT1Hpl9A"
      },
      "source": [
        "import urllib.request as urllib2\n",
        "import copy\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqWklqC14Qz0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pErZ_xMaqkKm"
      },
      "source": [
        "'''\n",
        "Random Forest Algorithm on Sonar Dataset\n",
        "Reference: [How to Implement Random Forest From Scratch in Python](http://machinelearningmastery.com/implement-random-forest-scratch-python/)\n",
        "'''\n",
        "\n",
        "def load_data():\n",
        "    '''\n",
        "    get Sonar data set and preprocess it\n",
        "    '''\n",
        "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "    rows = []\n",
        "    for line in urllib2.urlopen(data_url).readlines():\n",
        "        line = line.strip().decode().split(',')\n",
        "        features = [float(i) for i in line[:-1]]\n",
        "        label = [1 if line[-1] == 'M' else 0]\n",
        "        rows.append(features + label)\n",
        "    return rows"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoASaQwW4RtU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3G7pDxpqqMA"
      },
      "source": [
        "def subsample(dataset, ratio):\n",
        "    '''\n",
        "    simple random sampling with replacement\n",
        "    '''\n",
        "    sample = []\n",
        "    n_sample = round(len(dataset) * ratio)\n",
        "    while len(sample) < n_sample:\n",
        "        index = randrange(len(dataset))\n",
        "        sample.append(dataset[index])\n",
        "    return sample"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv3LHckI4TBR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cx2PEgzqugY"
      },
      "source": [
        "def test_split(dataset, index, value):\n",
        "    '''\n",
        "    split a dataset based on an attribute and an attribute value\n",
        "    '''\n",
        "    left  = []\n",
        "    right = []\n",
        "    for row in dataset:\n",
        "        if row[index] < value:\n",
        "            left.append(row)\n",
        "        else:\n",
        "            right.append(row)\n",
        "    return left, right"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7rVRgKg4Tl2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS9LCsYnqxIM"
      },
      "source": [
        "def gini_index(groups, class_values):\n",
        "    '''\n",
        "    calculate the Gini index for a split dataset\n",
        "    '''\n",
        "    gini = 0.0\n",
        "    for class_value in class_values:\n",
        "        for group in groups:\n",
        "            size = len(group)\n",
        "            if size == 0:\n",
        "                continue\n",
        "            proportion = [row[-1] for row in group].count(class_value) / float(size)\n",
        "            gini += (proportion * (1.0 - proportion))\n",
        "    return gini"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsMefoIV4UWv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOcs3dPq9sv"
      },
      "source": [
        "def get_split(dataset, n_features):\n",
        "    '''\n",
        "    select the best split point for a dataset\n",
        "    '''\n",
        "    # randomly selected n features\n",
        "    features = []\n",
        "    while len(features) < n_features:\n",
        "        index = randrange(len(dataset[0])-1)\n",
        "        if index not in features:\n",
        "            features.append(index)\n",
        "\n",
        "    # get set of uniq labels\n",
        "    class_values = list(set(row[-1] for row in dataset))\n",
        "\n",
        "    # init params\n",
        "    b_score  = 9999  # minimum Gini index\n",
        "    b_index  = None  # index of best column\n",
        "    b_value  = None  # best cut-off value of the best column\n",
        "    b_groups = None  # best groups\n",
        "\n",
        "    # loop through selected features to get the minimum Gini index\n",
        "    for col_index in features:\n",
        "        for row in dataset:\n",
        "            col_value = row[col_index]\n",
        "            groups = test_split(dataset, col_index, col_value)\n",
        "            gini = gini_index(groups, class_values)\n",
        "            if gini < b_score:\n",
        "                b_index  = col_index\n",
        "                b_value  = col_value\n",
        "                b_score  = gini\n",
        "                b_groups = groups\n",
        "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu2E3_pT4VIb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJMd98F0rBDo"
      },
      "source": [
        "def to_terminal(group):\n",
        "    '''\n",
        "    return the label with highest frequency\n",
        "    '''\n",
        "    labels = [row[-1] for row in group]\n",
        "    return max(set(labels), key=labels.count)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaJ4R-dJ4V0R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuRL7_2ErE6u"
      },
      "source": [
        "def split(node, max_depth, min_size, n_features, depth):\n",
        "    '''\n",
        "    create child splits for a node or make terminal\n",
        "    '''\n",
        "    left, right = node['groups']\n",
        "    del(node['groups'])\n",
        "\n",
        "    # check for a no split\n",
        "    if not left or not right:\n",
        "        node['left'] = node['right'] = to_terminal(left + right)\n",
        "        return\n",
        "\n",
        "    # check for max depth\n",
        "    if depth >= max_depth:\n",
        "        node['left']  = to_terminal(left)\n",
        "        node['right'] = to_terminal(right)\n",
        "        return\n",
        "\n",
        "    # process left child\n",
        "    if len(left) <= min_size:\n",
        "        node['left'] = to_terminal(left)\n",
        "    else:\n",
        "        node['left'] = get_split(left, n_features)\n",
        "        split(node['left'], max_depth, min_size, n_features, depth+1)\n",
        "\n",
        "    # process right child\n",
        "    if len(right) <= min_size:\n",
        "        node['right'] = to_terminal(right)\n",
        "    else:\n",
        "        node['right'] = get_split(right, n_features)\n",
        "        split(node['right'], max_depth, min_size, n_features, depth+1)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BaCQ31M4Wfk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJxMb4jCrJV-"
      },
      "source": [
        "\n",
        "def build_tree(train, max_depth, min_size, n_features):\n",
        "    root = get_split(train, n_features)\n",
        "    split(root, max_depth, min_size, n_features, 1)\n",
        "    return root"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w81K53yS4XrE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2QxdKcTrMUO"
      },
      "source": [
        "def predict(node, row):\n",
        "    '''\n",
        "    make a prediction with a decision tree\n",
        "    '''\n",
        "    if row[node['index']] < node['value']:\n",
        "        if isinstance(node['left'], dict):\n",
        "            return predict(node['left'], row)\n",
        "        else:\n",
        "            return node['left']\n",
        "    else:\n",
        "        if isinstance(node['right'], dict):\n",
        "            return predict(node['right'], row)\n",
        "        else:\n",
        "            return node['right']"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FocNtLMrQZ3"
      },
      "source": [
        "def bagging_predict(trees, row):\n",
        "    '''\n",
        "    make a prediction with a list of bagged trees\n",
        "    '''\n",
        "    predictions = [predict(tree, row) for tree in trees]\n",
        "    # return the label that is voted by most of the trees\n",
        "    return max(set(predictions), key=predictions.count)"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhbDvdzU4Ye1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBUVdwBcrT9t"
      },
      "source": [
        "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
        "    # train\n",
        "    trees = []\n",
        "    for i in range(n_trees):\n",
        "        sample = subsample(train, sample_size)\n",
        "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
        "        trees.append(tree)\n",
        "    # predict\n",
        "    predictions = [bagging_predict(trees, row) for row in test]\n",
        "    return(predictions)"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZTxdLh94ZMo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAtz7J1ErXXb"
      },
      "source": [
        "def cross_validation_split(dataset, n_folds):\n",
        "    '''\n",
        "    split the dataset into n folds\n",
        "    '''\n",
        "    dataset_copy = copy.copy(dataset)\n",
        "    fold_size = int(len(dataset_copy)/n_folds)\n",
        "    folds = []\n",
        "    for i in range(n_folds):\n",
        "        fold = []\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(dataset_copy))\n",
        "            fold.append(dataset_copy.pop(index))\n",
        "        folds.append(fold)\n",
        "    return folds"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1DsYxlL4Z8q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY5bveFmrZum"
      },
      "source": [
        "\n",
        "def accuracy_metric(actual, predicted):\n",
        "    '''\n",
        "    calculate accuracy percentage\n",
        "    '''\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEjjaT5x4asD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAGa1dvnrfK1"
      },
      "source": [
        "\n",
        "def evaluate_algorithm(dataset, algorithm, params, n_folds=5):\n",
        "    folds = cross_validation_split(dataset, n_folds)\n",
        "    scores = []\n",
        "    for fold in folds:\n",
        "        # prepare train set\n",
        "        trainset = copy.copy(folds)\n",
        "        trainset.remove(fold)\n",
        "        trainset = sum(trainset, []) # flatten trainset\n",
        "        # prepare test set\n",
        "        testset = copy.copy(fold)\n",
        "        # train & predict\n",
        "        predicted = algorithm(trainset, testset, **params)\n",
        "        # evaluate\n",
        "        actual = [row[-1] for row in fold]\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        scores.append(accuracy)\n",
        "    return scores\n"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFiVVOx4bUK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhtyKqKJjWeA",
        "outputId": "609770e4-39f4-45a2-c16c-8ffb92193088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    seed(1)\n",
        "    dataset = load_data()\n",
        "    n_features = int(sqrt(len(dataset[0])-1))\n",
        "    params = {\n",
        "        'n_trees': 10                # number of trees to be built\n",
        "        ,'sample_size': 1.0          # fraction to be randomly sampled for each tree\n",
        "        ,'n_features':  n_features   # number of features to be randomly selected to evaluate for each split\n",
        "        ,'max_depth': 10             # maximum depth of each tree\n",
        "        ,'min_size': 1               # minimum records number after split\n",
        "    }\n",
        "    for n_trees in [1, 5, 10, 20]:\n",
        "        params['n_trees'] = n_trees\n",
        "        scores = evaluate_algorithm(dataset, random_forest, params, n_folds=5)\n",
        "        print('Trees: %d' % n_trees)\n",
        "        print('Scores: %s' % scores)\n",
        "        print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trees: 1\n",
            "Scores: [51.21951219512195, 78.04878048780488, 58.536585365853654, 65.85365853658537, 53.65853658536586]\n",
            "Mean Accuracy: 61.463%\n",
            "Trees: 5\n",
            "Scores: [63.41463414634146, 60.97560975609756, 56.09756097560976, 60.97560975609756, 56.09756097560976]\n",
            "Mean Accuracy: 59.512%\n",
            "Trees: 10\n",
            "Scores: [65.85365853658537, 58.536585365853654, 68.29268292682927, 53.65853658536586, 75.60975609756098]\n",
            "Mean Accuracy: 64.390%\n",
            "Trees: 20\n",
            "Scores: [68.29268292682927, 56.09756097560976, 68.29268292682927, 68.29268292682927, 68.29268292682927]\n",
            "Mean Accuracy: 65.854%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4skZ-l_eq0qb"
      },
      "source": [
        ""
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6XK26_bjXZY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}